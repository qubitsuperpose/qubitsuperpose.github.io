---
title: 7차시 2:QGSS 2025 - 2 
layout: single
classes: wide
categories:
  - QGSS 2025
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---

## 10. 양자 컴퓨팅: 유틸리티 시대를 향한 정확한 계산

- 출처:[유틸리티 시대의 정확한 양자 컴퓨팅](https://www.youtube.com/watch?v=0BEZ5P0sP1w&list=PLOFEBzvs-VvoIfbpOb_geVnwFmbW6ij0m&index=10)

### **1. 왜 더 강력한 컴퓨터가 필요한가?**
스트리밍이나 이메일 같은 일반적인 작업에는 펜티엄 프로세서의 새로운 세대가 등장해도 극적인 변화가 없었을 수 있지만, 스마트폰이나 ChatGPT와 같은 놀라운 기술들은 수십 년간 **점점 더 강력한 컴퓨팅 머신을 만들려는 "광적인 집착"** 없이는 불가능했을 것입니다. Kandala 박사는 "만들면 찾아올 것(build it and they'll come)"이라는 신념을 가지고, 우리는 강력한 기계를 만들고 이를 활용하는 방법을 찾아내면서 문명으로서 새로운 애플리케이션을 발견할 수 있다고 강조합니다.

### **2. 고전 컴퓨터가 어려워하는 문제: 전자 구조 (Electronic Structure)**
고전 컴퓨터가 어려워하는 문제 중 하나는 **전자 구조** 문제입니다. 예를 들어, 두 원자 사이의 거리가 변함에 따라 이원자 분자의 전위 에너지(potential energy)가 어떻게 변하는지 설명하는 곡선은 화학 결합 길이를 찾고 **해리 에너지(dissociation energy)**를 계산하는 데 중요합니다. 화학 반응 속도는 이 해리 에너지의 정확도에 **기하급수적으로 민감**하기 때문에 매우 중요합니다.

이러한 문제는 시스템을 설명하는 해밀토니안(Hamiltonian)의 가장 낮은 에너지 상태(바닥 상태)를 찾는 **고유값 문제(eigenvalue problem)**로 귀결됩니다. N개의 스핀 궤도(spin orbital)가 있다면 2^N 개의 항목을 가진 행렬을 다루어야 하는데, 이는 55-60개의 스핀만 되어도 오늘날 가장 강력한 슈퍼컴퓨터의 메모리 용량을 초과하는 매우 어려운 작업이 됩니다. 1929년 디랙(Dirac)도 물리 법칙은 알지만, 정확한 적용은 너무 복잡하여 풀기 어렵다고 지적했습니다.

### **3. 고전적 근사 방법과 신뢰 구축**
이러한 문제를 해결하기 위해 **근사적인 고전적 방법**이 개발되어 왔습니다. 그러나 정확한 답을 모를 때 이러한 근사 방법에 대한 신뢰를 어떻게 구축할까요?
*   **작은 시스템 크기에서 벤치마킹**: 
    - 정확한 해를 구할 수 있는 작은 시스템에서 근사 방법의 성능을 검증합니다.
*   **특정 지점에서의 해석적 해**: 
    -   정확한 해를 알 수 있는 특수한 지점에서 근사 방법을 벤치마킹합니다.
*   **기존 방법과의 비교**: 
    -   새로운 알고리즘을 개발할 때 기존의 잘 확립된 고전적 방법들과 비교합니다.
*   **수렴성 확인**: 
    -   계산 자원(메모리, 실행 시간)을 체계적으로 늘려가면서 결과가 어떤 값으로 수렴하는지 확인합니다.

### **4. 양자 컴퓨터의 도전 과제: 높은 오류율**
양자 컴퓨터를 사용할 때도 유사한 신뢰 구축 과정이 필요합니다. 이를 위해서는 두 가지 조건이 필요합니다.
1.  **고전적인 무차별 대입 시뮬레이션을 넘어서는 규모**의 장치여야 합니다.
2.  **신뢰할 수 있는 해를 생성**할 수 있어야 합니다.

현재 양자 컴퓨터의 기본 빌딩 블록인 큐비트(qubit)는 고전 컴퓨터의 트랜지스터보다 **약 23~24배 더 오류가 발생하기 쉽습니다**. 이러한 높은 오류율에서 신뢰할 수 있는 해를 얻을 수 있을까요? 장기적인 해결책은 **양자 오류 수정(quantum error correction)**이지만, 아직은 초기 단계입니다.

### **5. 내결함성 이전의 해결책: 오류 완화 (Error Mitigation)**
내결함성(fault-tolerance) 양자 컴퓨터가 개발되기 전에도 신뢰할 수 있는 해를 얻을 수 있는 방법은 **오류 완화(error mitigation)**입니다.
*   **노이즈에 대한 관측량의 민감도**: 
    -   10,000개의 2-큐비트 게이트가 있는 회로에서 각 게이트의 충실도(fidelity)가 99.9%일 때, 최종 상태의 충실도는 5e-4로 매우 낮습니다. 하지만 시스템의 평균 자화(average magnetization)와 같은 특정 관측량은 노이즈에 덜 민감할 수 있습니다 (예: 세 번째 자리에서만 오차가 발생). 이는 특정 관측량이 노이즈의 영향을 덜 받을 수 있다는 희망을 줍니다.
*   **초기 시뮬레이션의 한계 (2017년)**: 
    -   2017년 4큐비트를 사용한 수소화 리튬(LiH) 분자 시뮬레이션에서 측정된 에너지는 화학자들이 요구하는 정확도에 비해 "끔찍하게(atrocious)" 높은 오류를 보였습니다.
*   **오류 완화 기법의 등장**: IBM에서 개발된 **오류 완화** 방법은 다음과 같습니다:
    1.  장치의 **노이즈를 특성화**합니다.
    2.  노이즈를 **제어된 방식으로 조작**합니다.
    3.  노이즈의 **영향을 상쇄**합니다.
    이는 노이즈 캔슬링 헤드폰이나 휴대폰과 같은 일상생활의 기술과 유사한 원리입니다.
*   **제로 노이즈 외삽 (Zero Noise Extrapolation, ZNE)**: 한 가지 오류 완화 기법인 ZNE는 다음과 같이 작동:
    *   기본 노이즈 수준에서 양자 회로를 실행하여 결과를 얻습니다.
    *   노이즈 모델을 사용하여 노이즈를 정밀하게 증폭(예: 1.2배, 1.6배)하여 더 많은 노이즈가 있는 상태에서 다시 측정합니다.
    *   이러한 측정값들을 결합하여 **"제로 노이즈" 극한으로 외삽**하여 이상적인 결과에 매우 가까운 값을 추정.
*   **개선된 LiH 시뮬레이션 (2019년)**: 
    -   ZNE를 사용하여 4큐비트 LiH 시뮬레이션을 다시 시도한 결과, 이상적인 결과와 훨씬 더 잘 일치하는 결과를 얻었습니다.

### **6. 양자 유틸리티 실험 (2023년)**
이제 오류 완화 기술이 대규모 장치에서 신뢰할 수 있는 해를 생성할 수 있는지에 대한 질문으로 넘어갑니다.
*   **IBM의 프로세서 개발**: 
    -   IBM은 1,000큐비트 이상의 프로세서를 개발했으며, 이미 65~100큐비트 수준에서 고전적인 무차별 대입 시뮬레이션으로는 불가능한 규모에 도달했습니다.
*   **127큐비트 양자 유틸리티 실험**: 
    -   2023년에 127큐비트 장치(Eagle)를 사용하여 상호작용하는 스핀 시스템의 자화 진화를 시뮬레이션하는 실험이 수행되었습니다.
    *   **실험 설정**: 
        -   127큐비트 모두와 최대 15개의 얽힘 레이어를 사용하는 양자 회로를 통해 외부 자기장의 변화에 따른 자화의 진화를 연구했습니다.
    *   **오류 완화의 효과**: 
        -   오류 완화 없이 측정된 녹색 선은 큰 오차를 보였지만, 오류 완화를 적용한 파란색 선은 훨씬 나은 결과를 보여주었습니다.
    *   **검증의 어려움**: 
        -   127큐비트는 고전적인 무차별 대입 시뮬레이션으로는 불가능한 규모였기 때문에, 초기에는 이 결과가 의미가 있는지 알 수 없었습니다.
    *   **"라이트 콘(Light Cone)" 기법을 통한 검증**: 
        -   캘리포니아 버클리 대학의 연구자들이 **"영향의 라이트 콘"**이라는 개념을 사용하여, 개별 스핀의 국소 관측량(local observables)에 영향을 미치는 큐비트와 게이트의 수가 전체 회로보다 훨씬 적다는 점을 이용했습니다. 이를 통해 훨씬 적은 수의 큐비트에 대해 정확한 대각화를 수행하여 **이상적인 결과를 도출**할 수 있었고, 오류 완화를 적용한 양자 컴퓨터의 결과가 **이상적인 결과와 매우 잘 일치함**을 확인했습니다. 이는 장치와 방법에 대한 큰 신뢰를 주었습니다.
    *   **정확한 검증을 넘어서**: 
        -   이 검증을 통해 얻은 신뢰를 바탕으로, 라이트 콘 기법으로도 정확한 해를 얻을 수 없는 더 깊은 회로까지 실험을 확장했습니다. 이 단계에서는 정확한 해가 없으므로, 양자 컴퓨터의 결과(오류 완화 포함)를 여러 다른 고전적 근사 방법의 결과와 비교했습니다. 양자 컴퓨터의 결과는 이들 고전적 근사 방법들 간의 **변동성 범위 내에 위치**하며, 이는 양자 컴퓨터가 **"유틸리티 규모(utility scale)"**에서 신뢰할 수 있는 계산을 수행할 수 있음을 의미합니다.

### **7. 최신 발전 및 미래 방향**
이러한 시연 이후 양자 컴퓨팅 분야에는 극적인 발전이 있었습니다.
*   **적용 사례 증가**: 
    -   유틸리티 규모의 큐비트를 사용하는 실험이 기하급수적으로 증가하고 있습니다.
*   **소프트웨어 속도 향상**: 
    -   2023년 유틸리티 실험을 재실행하는 데 약 75배의 속도 향상이 있었고, 5일 걸리던 실험이 몇 시간 만에 가능해졌습니다.
*   **하드웨어 개선**: 
    -   새로운 Heron 아키텍처는 2-큐비트 오류율을 5배 개선하여 오류 완화 오버헤드를 줄였습니다.
*   **노이즈 안정화**: 
    -   노이즈를 특성화하고 조작하는 과정에서 노이즈가 표류(drift)하는 문제를 해결하기 위한 노이즈 안정화 방법들이 개발되고 있습니다.
*   **양자 정보 처리 방법 개발**: 
    -   내결함성 이전의 장치에서 신뢰할 수 있는 정확한 해를 얻기 위한 강력한 양자 정보 처리 방법들이 지속적으로 개발되고 있습니다.
*   **양자 중심 슈퍼컴퓨팅 (Quantum-Centric Supercomputing)**: 
    -   양자와 고전을 결합하여 양자 단독 또는 고전 단독으로는 불가능했던 작업을 수행하는 새로운 프레임워크가 부상하고 있습니다. 이는 오류 완화 오버헤드를 줄이는 데도 기여합니다.
*   **양자 화학의 비약적 발전**: 
    -   2017년에 4~6큐비트 수준이던 양자 화학 시뮬레이션은 이제 최대 77큐비트의 유틸리티 규모에서 최첨단 고전적 방법과 경쟁하고 있습니다.

**현재의 노이즈가 많고 내결함성이 없는 양자 컴퓨터로도 고전적인 무차별 대입 시뮬레이션을 넘어서는 비자명한(non-trivial) 규모에서 정확한 계산을 수행할 수 있다**는 점을 강조합니다. 속도와 시스템 품질의 향상, 하드웨어 오류율 개선, 그리고 고성능 컴퓨팅(HPC)과의 통합이 결합된다면, 우리는 곧 **"유틸리티(utility)"를 넘어 "이점(advantage)"의 시대**로 나아갈 수 있을 것입니다.

## 11. 샘플 기반 양자 대각화(Sample-Based Quantum Diagonalization, SQD) 소개

- 출처:[A Deep Dive Into Sample-Based Quantum Diagonalization Methods](https://www.youtube.com/watch?v=VZadH9L9ZIM&list=PLOFEBzvs-VvoIfbpOb_geVnwFmbW6ij0m&index=11)

*   **샘플 기반 양자 대각화(Sample-Based Quantum Diagonalization, SQD)**라는 하이브리드 양자-고전 기법에 대해 설명한다. 이 기술의 목표는 **양자 다체 시스템의 상태와 고유 벡터를 연구**하는 것으로, 양자 화학 및 재료 과학 분야(예: 신소재 개발, 신약 개발, 배터리 설계)에서 **계산적으로 어려운 에너지 추정 문제를 해결**하는 데 응용됩니다.

*   기존의 양자 알고리즘인 양자 위상 추정(Quantum Phase Estimation)은 정확한 해를 보장하지만, **깊은 회로와 내결함성 양자 프로세서**를 필요로 합니다. 반면, 근시일(near-term) 양자 컴퓨터에 더 적합한 변분 양자 알고리즘(Variational Quantum Algorithms, VQAs)은 **얕은 회로 깊이**를 가지지만, **수렴 보장이 없고** 화학 문제의 경우 **상당한 측정 오버헤드**가 발생합니다. SQD는 이러한 문제점들을 해결하기 위해 제안된 방법입니다.

### 1. **문제 정의 및 가정**

우리가 풀고자 하는 문제는 **지수적으로 거대한 행렬(해밀토니안)**의 **가장 작은 고유값(바닥 상태 에너지)과 해당 고유 벡터(바닥 상태)**를 찾는 것입니다. 이 행렬은 시스템 크기(예: 분자의 전자 수)에 따라 차원이 지수적으로 증가합니다. 하지만, 우리가 관심 있는 전형적인 다체 문제의 해밀토니안은 **지수적으로 희소(sparse)하다**는 특징이 있습니다. 즉, 행렬의 행 또는 열당 0이 아닌 요소의 수는 시스템 크기에 따라 다항식적으로 증가합니다.

또한, 이 방법은 우리가 관심을 갖는 고유 벡터들이 **다항식적 지지(polynomial support)**를 가질 것이라는 추가적인 가정을 사용합니다. 이는 대부분의 성분들이 지배적인 차원에 비해 훨씬 작은 진폭을 가진다는 의미입니다. 예를 들어, 낮은 에너지 궤도에 전자가 주로 채워지는 시스템의 바닥 상태를 상상할 수 있습니다. 이러한 통찰력은 바닥 상태를 설명하는 데 덜 중요할 수 있는 힐베르트 공간의 차원을 제거할 수 있게 합니다.

### 2. **샘플 기반 양자 대각화(SQD)의 작동 원리**

SQD는 이 가정을 활용하여 문제를 해결합니다. 만약 우리가 관련 있는 차원들을 알고 있다면, 지수적으로 거대한 해밀토니안을 **관련 전자 배치(electronic configurations)의 부분 공간에 투영하여** 대각화 문제를 훨씬 더 작은, 즉 **다루기 쉬운 문제**로 만들 수 있습니다. SQD의 핵심은 이 **관련 차원을 식별**하는 것입니다.

1.  **고전적 접근법(Selected Configuration Interaction, SCI)**: 
    -   고전적으로는 휴리스틱, 물리적 직관, 섭동 이론에 기반한 **선택적 배치 상호작용(Selected Configuration Interaction)**과 같은 트리(tree-like) 검색 방법이 있습니다. 이 방법은 작은 부분 공간에서 바닥 상태 근사치로 시작하여 해밀토니안을 적용하여 차원을 확장하고, 기준에 따라 차원을 선택한 후 대각화를 수행하며, 수렴할 때까지 이 과정을 반복합니다.

2.  **양자적 접근법(SQD)**: 
    -   SQD는 **양자 회로(S)**를 사용하여 문제의 **관련 자유도(relevant degrees of freedom)**를 식별합니다. 양자 회로에서 계산 기저 측정(computational basis measurement)을 수행하면 힐베르트 공간에 대한 확률 분포가 정의됩니다. 이로부터 **자주 샘플링되는 전자 배치(비트 문자열)**를 선택하여 해밀토니안을 투영하고 대각화할 부분 공간을 정의합니다.

### 3. **양자 잡음(Noise) 처리: 구성 복구(Configuration Recovery)**

양자 프로세서에서는 양자 잡음의 영향을 다루어야 합니다. SQD는 **구성 복구(configuration recovery)**라는 절차를 통해 이를 처리합니다.

*   **내재적 복원력**: 
    -   양자 장치에서 샘플을 수집하고 해밀토니안을 부분 공간에 투영하여 대각화하는 과정 자체는 잡음의 영향에 대한 **내재적인 복원력**을 가집니다. 예를 들어, 잡음으로 인해 바닥 상태 설명에 참여하지 않는 비트 문자열이 샘플링되더라도, 대각화 과정은 해당 비트 문자열에 **0의 가중치를 할당하여 걸러낼 수 있습니다**.

*   **자기 일관적 구성 복구(Self-Consistent Configuration Recovery)**: 
    -   효율성을 더욱 높이기 위해 **자기 일관적 구성 복구**라는 방법을 사용합니다. 이 방법은 물리적 직관을 활용.
    *   예를 들어, 예상되는 **전자 수(number of electrons)**가 잘못된 비트 문자열은 쉽게 식별할 수 있습니다.
    *   또한, **평균 궤도 점유율(average orbital occupancies)**이라는 바닥 상태 고유의 속성을 활용합니다. 어떤 궤도에 전자가 많을 것으로 예상되면, 해당 궤도에 해당하는 비트(bit)가 잘못된 경우 이를 뒤집을 확률을 높이는 **확률적 비트 플리핑(probabilistic bit flipping)**을 수행하여 올바른 전자 수를 복구합니다.
    *   이 평균 궤도 점유율은 처음에는 모르지만, **반복적으로 계산하고 정제**하여 자기 일관적으로 수렴할 때까지 사용됩니다.

수치 실험 결과, 자기 일관적 구성 복구는 에너지 오류를 **상당히 낮출 뿐만 아니라**, 동일한 정확도(예: 10 milliHartrees)를 달성하는 데 필요한 신호의 양(alpha)을 **20%에서 2%로 크게 줄이는 효과**를 보여주었습니다. 이는 구성 복구가 SQD 워크플로우의 핵심 부분임을 의미합니다.

### 4. **양자 회로 선택**

샘플을 생성하는 양자 회로는 두 가지 주요 선택지가 있습니다.

1.  **휴리스틱 회로(Heuristic Choices) - SQD**:
    *   **물리적으로 영감을 받은 Ansatz**를 사용합니다.
    *   전자 구조 문제에 사용되는 대표적인 예는 **국소 유니타리 클러스터 제스토(Local Unitary Cluster Jastrow, LUCC) 회로**입니다.
    *   LUCC 회로는 **유니타리 결합 클러스터(unitary coupled cluster)**에서 파생된 물리적 동기 부여와 **하드웨어 친화성**을 결합하여, 하드웨어 효율적인 회로와 물리적 동기 부여 Ansatz의 중간 지점을 찾습니다.
    *   이 회로는 고전적 계산 결과(예: 결합 클러스터 이론)를 입력 매개변수로 사용할 수 있으며, 특정 한계에서는 고전적 방법보다 나은 성능을 보일 수 있습니다.

2.  **수렴 보장 회로(Provable Convergence Guarantees) - 샘플 기반 크릴로 양자 대각화(SKQD)**:
    *   **크릴로 기저(Krylov basis)의 멤버로부터 샘플링**합니다.
    *   이 방법에서는 참조 상태를 준비한 다음, 다양한 시간 슬라이스에 걸쳐 **시간 진화(time evolution)**를 수행하고 각 시간에서 샘플을 수집합니다.
    *   크릴로 기저에서 샘플링하는 경우, 참조 상태가 실제 바닥 상태와 충분한 오버랩을 가지고, 갭이 기하급수적으로 사라지지 않으며, 바닥 상태가 희소하다는 조건이 충족되면 **바닥 상태 오차가 회로 수 및 샘플 수에 따라 효율적으로 수렴함**을 증명할 수 있습니다.
    *   분자 해밀토니안은 항의 수가 많아 시간 진화 회로 구현이 어려울 수 있으므로, SKQD는 **격자 모델(lattice models)**, 특히 불순물 모델(impurity models)에 중점을 둡니다.

### 5. **응용 분야 및 성과**

IBM에서는 SQD 및 SKQD를 다양한 시스템에 성공적으로 적용했습니다.

*   **분자 시스템 (SQD)**:
    *   **질소 분자 해리**: 
        -   58 큐비트 실험으로, 강력하게 상관된 과정인 질소 삼중 결합의 끊어짐을 정성적으로 정확하게 묘사.
    *   **철-황 클러스터 (Fe2S2, Fe4S4)**: 
        -   45 큐비트 및 77 큐비트 실험을 통해, 이온 원자의 자기 결합으로 인한 강한 상관관계를 연구했습니다. 에너지 분산 분석(energy variance analysis)을 통해 바닥 상태 에너지 외삽값이 최첨단 고전적 방법(DMRG)과 매우 잘 일치함을 보여주었습니다.
    *   **77 큐비트, 3,500 2-큐비트 게이트**: 
        -   이 대규모 실험은 무작위 비트 문자열에서 얻은 결과보다 양자 장치에서 유용한 신호를 추출할 수 있음을 입증했습니다.
    *   다른 응용으로는 초분자 상호작용, 비점유 시스템, 임베딩 방법과의 결합을 통한 유기 분자 연구, 그리고 들뜬 상태(excited states) 연구까지 확장되었습니다. **최대 84 큐비트, 5,000 2-큐비트 게이트**까지 이 방법을 적용했습니다.

*   **격자 모델 (SKQD)**:
    *   **단일 불순물 앤더슨 모델(Single Impurity Anderson Model)**: 
        -   이 모델은 실제 재료 계산을 단순화하고 수치 기술을 벤치마킹하는 데 중요합니다.
    *   **85 큐비트, 6,000 2-큐비트 게이트**: 
        -   두 단계로 실험을 진행하여 (운동량 기저에서의 초기 계산 및 궤도 회전을 통한 희소성 증가), 지상 상태 에너지의 상대 오차가 10^-4 ~ 10^-5 수준으로 매우 높았습니다.
    *   **스핀-스핀 쌍 상관 함수(spin-spin pairwise correlation functions)**와 같은 다른 물리량도 고전적 방법(DMRG)과 매우 잘 일치함을 보여주었습니다.

### 6. **주요 통찰력**

*   **양자 중심 슈퍼컴퓨팅(Quantum-Centric Supercomputing)**: 
    -   SQD는 양자와 고성능 컴퓨팅(HPC) 자원이 협력하여 물리 시스템을 시뮬레이션하는 "양자 중심 슈퍼컴퓨팅"의 한 예입니다. 고전적 분산 컴퓨팅이 빅데이터 처리를 담당하고, 양자 프로세서는 소수의 대규모 양자 회로 실행에 최적화된 역할을 수행합니다.
*   **확장성**: 
    -   이 방법은 브루트 포스 고전 시뮬레이션이나 정확한 대각화의 범위를 넘어 **최대 85 큐비트 및 6,000 2-큐비트 게이트**를 가진 시스템을 시뮬레이션할 수 있도록 했습니다.
*   **효율적인 수렴**: 
    -   SKQD의 경우, 양자 회로 수 및 각 회로에서 수집된 샘플 수에 따라 실제 바닥 상태 에너지로 효율적으로 수렴한다는 증명이 있습니다.
*   **희소성 가정**: 
    -   SQD와 SKQD는 바닥 상태가 다항식 수의 계산 기저 상태에 의해 지지될 때 가장 잘 작동합니다. 이 가정이 없더라도, 부분 공간 차원을 늘려 방법의 성능을 평가하는 휴리스틱 방법으로 활용할 수 있습니다.
*   **개별 샘플 처리**: 
    -   SQD는 양자 데이터를 **개별 샘플 수준에서 처리**하여 기대값 계산을 위한 단순 평균화를 넘어 가장 유용한 정보를 추출합니다.


## 12. 양자 오류 정정(Quantum Error Correction, QEC)

- 출처:[양자 오류 정정의 기초 I](https://www.youtube.com/watch?v=fFOEOukIcUU&list=PLOFEBzvs-VvoIfbpOb_geVnwFmbW6ij0m&index=12)

### 1.**양자 오류 정정의 필요성**

양자 컴퓨팅은 기존 컴퓨팅으로는 해결하기 어려운 복잡한 문제에 대한 효율적인 해결책을 제시할 잠재력이 있지만, 몇 가지 **중대한 난제**를 극복해야 합니다.

1.  **양자 정보의 극심한 취약성**: 
    -   양자 정보는 매우 깨지기 쉬워서 "바라보기만 해도 망가질 수 있다"고 표현됩니다.
2.  **디코히어런스(Decoherence)**: 
    -   환경과의 원치 않는 상호작용으로 인해 양자 정보가 환경으로 새어 나가면서, 양자 컴퓨터에 저장된 정보가 점점 더 고전적으로 행동하게 됩니다.
3.  **양자 연산의 제한된 정확도**: 
    -   양자 게이트는 물리적 장치의 불완전성 때문에 완벽하게 수행될 수 없으며, 이러한 작은 부정확성들이 수천, 수백만 개의 게이트에서 누적되면 최종 결과가 크게 달라질 수 있습니다.

이러한 문제들로 인해, 대규모 양자 컴퓨팅을 구현하려면 양자 오류 정정이 **필수적일 것**으로 예상됩니다.

### 2. **오류 정정의 기본 개념: 고전적 반복 코드**

양자 오류 정정은 고전적 오류 정정 개념을 기반으로 합니다. **3-비트 반복 코드**는 가장 기본적인 오류 정정 코드의 예시입니다.

*   **인코딩(Encoding)**: 
    -   하나의 비트를 세 번 반복하여 인코딩합니다 (예: 0 → 000, 1 → 111).
*   **오류 발생**: 만약 한 비트만 뒤집히는 오류(비트 플립)가 발생하더라도:
    *   **디코딩(Decoding)**: 세 비트 중 두 번 나타나는 값, 즉 **다수결 값**을 계산하여 원래 비트를 유추.
*   **성능**: 
    -   이 코드는 최대 하나의 비트 플립 오류를 정확하게 정정할 수 있지만, 두 개 이상의 비트가 뒤집히면 실패.
*   **오류 확률 감소**: 
    -   각 비트가 확률 P로 독립적으로 뒤집히는 이진 대칭 채널(binary symmetric channel)을 통해 비트를 전송할 때, 3-비트 반복 코드를 사용하면 P가 1/2보다 작을 경우 오류 확률을 감소시킬 수 있습니다.

### 3. **양자 비트(Qubit)에 대한 반복 코드의 적용 및 한계**

고전적 반복 코드를 큐비트에 적용하는 것을 고려할 수 있지만, 이는 완벽한 양자 오류 정정 코드가 아닙니다.

*   **큐비트 인코딩**: 
    -   $\| \alpha \|0\rangle + \beta \|1\rangle$와 같은 큐비트를 $\|\alpha \|000\rangle + \beta \|111\rangle$로 인코딩합니다. 이는 양자 상태를 단순히 세 번 반복하는 것(예: $\|S\rangle \otimes \|S\rangle \otimes \|S\rangle$)과는 다릅니다. 이는 **복제 금지 정리(no-cloning theorem)** 때문에 불가.
*   **비트 플립(X 오류) 정정**:
    *   만약 하나의 큐비트에서 **폴리 X 연산(비트 플립)** 오류가 발생하면, 특정 양자 회로를 사용하여 **상태를 붕괴시키지 않고** 오류의 위치를 파악할 수 있습니다.
    *   이 회로는 큐비트 쌍 간의 **패리티(parity) 검사**를 수행하여 **증후(syndrome)**라는 측정 결과를 생성합니다. 예를 들어, 가운데 큐비트에 오류가 나면 증후는 11이 됩니다.
    *   이 증후를 통해 오류 발생 위치를 파악하고, 해당 큐비트에 X 게이트를 적용하여 오류를 정정할 수 있습니다.
*   **위상 플립(Z 오류)에 대한 실패**:
    *   하지만 이 3-비트 반복 코드는 **위상 플립 오류(Z 오류)**를 전혀 감지하지 못합니다.
    *   가령, 위상 플립 오류가 발생하더라도 증후 측정 결과는 00으로 나타나, 마치 오류가 없는 것처럼 잘못 판단하게 됩니다.


### 4. **위상 플립 오류 감지를 위한 반복 코드의 변형**

위상 플립 오류를 처리하기 위해 3-비트 반복 코드를 수정할 수 있습니다.

*   **하다마르 게이트(Hadamard gate) 적용**: 
    -   원래의 인코딩 회로에 인코딩된 각 큐비트에 하다마르 게이트를 적용합니다. 하다마르 게이트는 $\|0\rangle$를 $\|+\rangle$로, $\|1\rangle$를 $\|-\rangle$로 변환합니다.
*   **위상 플립을 비트 플립으로 변환**: 
    -   이 새로운 인코딩에서 위상 플립 오류(Z 게이트)는 $\|+\rangle$ 상태를 $\|-\rangle$ 상태로, $\|-\rangle$ 상태를 $\|+\rangle$ 상태로 변환합니다. 이는 마치 비트 플립처럼 행동하게 됩니다.
*   **오류 감지 회로 수정**: 
    -   기존의 오류 감지 회로 앞뒤에 하다마르 게이트를 추가하여 위상 플립 오류를 비트 플립 오류처럼 감지하고 정정할 수 있습니다.
*   **한계**: 
    -   이 코드는 위상 플립 오류를 정정할 수 있지만, 이제는 **비트 플립 오류를 정정할 수 없게 됩니다**.


### 5. **9-큐비트 쇼어 코드: 비트 및 위상 플립 오류 정정**

두 가지 유형의 오류(비트 플립 및 위상 플립)를 모두 정정하기 위해, 위의 두 코드를 **결합**해 **9-큐비트 쇼어 코드**를 만듦.

*   **코드 구성**:
    1.  먼저, 원래 큐비트를 위상 플립 오류를 감지하는 **수정된 3-비트 반복 코드**(외부 코드)로 인코딩하여 3개의 큐비트를 만듭니다.
    2.  그 다음, 이 3개의 큐비트 각각을 원래의 **3-비트 반복 코드**(내부 코드)로 독립적으로 인코딩하여 총 9개의 큐비트를 만듭니다.

*   **오류 정정 과정**:
    *   **비트 플립(X 오류) 정정**: 
        -   9개의 큐비트를 각각 3개 큐비트로 이루어진 세 개의 "블록"으로 나눕니다. 만약 어느 하나의 큐비트에 X 오류가 발생하면, 각 블록에 대해 독립적으로 비트 플립 오류를 확인하고 정정하여 원본 인코딩 상태를 복구할 수 있습니다. 각 블록에 최대 하나의 X 오류만 발생하면, 여러 블록에 X 오류가 있어도 정정 가능합니다.
    *   **위상 플립(Z 오류) 정정**: 
        -   Z 오류는 외부 코드에 의해 정정됩니다. 특정 블록 내의 어떤 큐비트에서 Z 오류가 발생하더라도 효과는 해당 블록의 모든 큐비트에 동일하게 나타나므로, 해당 블록의 어느 큐비트에 Z 게이트를 적용하여 오류를 정정할 수 있습니다. 이는 오류 정정 코드의 **축퇴(degeneracy)**의 한 예시입니다.
    *   **비트 플립 및 위상 플립(Y 오류) 정정**: 
        -   쇼어 코드는 비트 플립과 위상 플립 오류를 **완전히 독립적으로** 감지하고 정정할 수 있습니다. X와 Z 게이트가 반교환 관계(XZ = -ZX)이지만, 여기서 발생하는 전역 위상(global phase) -1은 오류 정정 과정에 영향을 미치지 않습니다. 따라서 X 오류를 먼저 정정하든 Z 오류를 먼저 정정하든 상관없습니다.


### 6. **임의의 양자 오류 정정**

쇼어 코드는 X, Z, 또는 두 가지 오류를 모두 포함하는 **임의의 단일 큐비트 오류**를 정정할 수 있습니다.

*   **임의의 단일 큐비트 유니타리 오류**: 
    -   어떤 임의의 유니타리 행렬 U도 **항등 행렬(I)**과 세 개의 **폴리 행렬(X, Y, Z)**의 선형 조합으로 표현 가능.
    *   오류가 발생하면, 증후 측정을 통해 오류가 어떤 폴리 연산(I, X, Y, Z 중 하나)에 해당하도록 **상태가 효과적으로 붕괴(project)**됩니다.
    *   오류가 폴리 연산으로 "이산화"되면, 해당 폴리 연산을 되돌리는 게이트를 적용하여 오류를 정정할 수 있다.
    *   오류와 증후 측정으로 인해 생성된 무작위성(엔트로피)은 증후 큐비트로 이동하며, 이 큐비트는 나중에 폐기하거나 재설정할 수 있어 시스템에서 제거됩니다.

*   **임의의 (비-유니타리) 오류**: 
    -   **크라우스 표현(Krauss representation)**을 사용하면, 유니타리 오류와 유사하게 임의의 비-유니타리 오류도 여러 개의 크라우스 행렬의 선형 조합으로 표현할 수 있습니다. 각 크라우스 행렬 또한 폴리 행렬의 선형 조합으로 표현되므로, 증후 측정과 이산화 과정을 통해 정정할 수 있습니다.


### 7. **쇼어 코드의 성능**

쇼어 코드는 역사상 최초의 양자 오류 정정 코드로서 중요한 발견이지만, 실용적인 측면에서는 한계가 있습니다.

*   **노이즈 모델**: 
    -   각 큐비트에서 확률 P로 오류가 독립적으로 발생하는 간단한 노이즈 모델을 가정할 때, 쇼어 코드는 단일 큐비트의 모든 폴리 오류를 정정할 수 있습니다.
*   **손익분기점(Break-even point)**: 
    -   P 값이 너무 크면 코드를 사용하는 것이 오히려 상황을 악화시킬 수 있습니다. 쇼어 코드의 경우, 손익분기점은 대략 **3.25%**입니다. 즉, 오류 확률 P가 3.25%보다 작을 때만 쇼어 코드가 실제 큐비트 오류 확률보다 논리 큐비트의 오류 확률을 낮출 수 있습니다.
*   **실용적 한계**: 
    -   3.25%는 고전적 3-비트 반복 코드의 50% 손익분기점에 비해 매우 낮은 값으로, 양자 정보를 보호하는 것이 훨씬 어렵다는 것을 보여줍니다. 따라서 쇼어 코드는 개념을 설명하는 데 훌륭하지만, 실제 대규모 양자 컴퓨터에서는 더 나은 코드가 필요할 수 있습니다.

## 13. 안정자(Stabilizer) 형식론과 CSS 코드

- 출처:[Basics of Quantum Error Correction II](https://www.youtube.com/watch?v=BnPc_IEL6qE&list=PLOFEBzvs-VvoIfbpOb_geVnwFmbW6ij0m&index=13)

### **1. 양자 오류 수정의 기초**
이론적으로 양자 오류 수정이 가능하다는 것을 보여주는 **9큐비트 쇼어 코드**와 **오류의 이산화(discretization of errors)** 현상에 대한 첫 번째 강의 내용을 바탕으로 진행됩니다. 오류의 이산화는 임의의 양자 오류를 비트 플립(X 오류)과 위상 플립(Z 오류)으로 효과적으로 투영하여 수정할 수 있도록 합니다.

### **2. 폴리 연산 (Pauli Operations)**

안정자 형식론을 이해하기 위한 기본 도구인 폴리 연산에 대해 먼저 알아봅시다.

*   **폴리 행렬 (Pauli Matrices)**: 
    *   2x2 항등 행렬(I)과 세 개의 비항등 폴리 행렬(X, Y, Z)이 있습니다.
    *   이 네 행렬은 모두 **유니타리(unitary)**하고 **헤르미트(Hermitian)**하며, 큐비트에 대한 연산 또는 오류로 간주될 수 있습니다.
    *   비항등 폴리 행렬 X, Y, Z는 서로 **반교환(anti-commute)**합니다 (예: XY = -YX). 이 반교환 관계는 오류 검출에 중요합니다.
    *   각 폴리 행렬은 자기 자신에 대한 역행렬이며 (X² = I, Y² = I, Z² = I), 두 개의 다른 비항등 폴리 행렬을 곱하면 ±i에 남은 비항등 폴리 행렬이 됩니다 (예: XZ = -iY, YX = iZ).
    *   **Y 연산은 X 오류와 Z 오류가 동시에 발생한 것과 같습니다** (Y ≡ XZ, 전역 위상을 제외하고). 이 때문에 양자 오류 수정에서는 주로 X와 Z 오류에 초점을 맞춥니다.
*   **n-큐비트 폴리 연산**: 
    -   n개의 폴리 행렬의 텐서곱(tensor product)을 의미합니다 (예: X⊗I⊗Z).
*   **가중치 (Weight)**: 
    -   n-큐비트 폴리 연산에서 비항등 폴리 행렬의 개수를 나타냅니다. 직관적으로는 연산이 비자명하게(non-trivially) 작용하는 큐비트의 개수입니다. 양자 오류 수정 코드는 특정 가중치 이하의 오류를 검출하고 수정하도록 설계됩니다.
*   **폴리 연산의 생성 집합 (Generated Set)**: 
    -   특정 폴리 연산들을 서로 곱하여 얻을 수 있는 모든 행렬의 집합입니다. 예를 들어, X, Y, Z가 생성하는 집합을 **폴리 군(Pauli Group)**이라고 합니다.
*   **측정으로서의 폴리 연산 (Pauli Measurements)**: 
    -   폴리 행렬은 측정 연산(관측량, observables)도 나타냅니다.
    *   각 폴리 행렬은 고유값(eigenvalue)과 고유 벡터(eigenvector)로 정의되는 **투영 측정(projective measurement)**과 연관될 수 있습니다.
    *   예를 들어, X 측정은 큐비트의 ± 기저에 대한 측정이며, Z 측정은 표준 기저(0/1) 측정과 같습니다.
    *   이러한 측정은 **위상 추정(phase estimation)**을 사용하여 수행할 수 있습니다.
    *   **Z⊗Z 측정**은 두 큐비트의 개별 Z 측정과 다릅니다. 이는 두 큐비트의 **패리티(parity)**를 측정하는 것과 같다.


### **3. 안정자 형식론 (Stabilizer Formalism)**

안정자 형식론은 광범위한 양자 오류 수정 코드인 **안정자 코드(Stabilizer Codes)**를 지정하고 분석하는 수학적 도구

*   **3비트 반복 코드 예시**:
    *   주어진 큐비트 상태 $\|ψ⟩ = α\|0⟩ + β\|1⟩$를 $α\|000⟩ + β\|111⟩$로 인코딩합니다.
    *   이 인코딩된 상태 $\|ψ⟩$는 두 개의 폴리 연산 **ZZI (Z⊗Z⊗I)**와 **IZZ (I⊗Z⊗Z)**의 고유 벡터(eigenvector)이며, 고유값은 항상 +1입니다.
    *   이 ZZI와 IZZ 연산을 **안정자 생성자(Stabilizer Generators)**라고 부릅니다. 이들을 통해 생성되는 집합이 코드의 **안정자(Stabilizer)**입니다.
    *   이 안정자 생성자들을 관측량으로 측정하면 **패리티 검사 회로(parity check circuit)**를 통해 오류 여부를 확인할 수 있습니다.
*   **오류 검출 (Error Detection)**:
    *   오류 E가 발생하면 인코딩된 상태가 변화합니다.
    *   안정자 생성자와 오류 연산 간의 **교환(commute) 또는 반교환(anti-commute)** 여부에 따라 측정 고유값이 결정됩니다.
        *   교환하는 경우: +1 고유값.
        *   반교환하는 경우: -1 고유값.
    *   각 안정자 생성자에 대한 고유값(+1 또는 -1)의 벡터를 **증후군(Syndrome)**이라고 합니다. 증후군은 발생한 오류가 무엇인지 알려주며, 오류 수정을 가능하게 합니다.
    *   증후군은 상태 공간과 가능한 모든 폴리 오류를 같은 크기의 부분 공간/집합으로 나눕니다.
*   **안정자 코드의 일반적인 정의**:
    *   n개의 큐비트를 사용하는 인코딩을 위한 **n-큐비트 폴리 연산 P1, ..., PR**을 안정자 생성자로 선택합니다.
    *   안정자 생성자는 다음 조건을 만족해야 합니다:
        1.  모든 안정자 생성자가 **서로 교환(commute)**해야 합니다. 이는 측정 순서에 관계없이 같은 결과를 보장합니다.
        2.  안정자 생성자들은 **최소 생성 집합(minimal generating set)**을 형성해야 합니다. 즉, 어느 하나라도 제거하면 더 작은 안정자가 됩니다.
        3.  최소한 하나의 0이 아닌 벡터가 모든 안정자 생성자에 의해 고정되어야 합니다. 이는 **-I (n 큐비트에 대한 -1 곱하기 항등 행렬)**가 안정자에 포함되지 않는 것과 동등하며, 유효한 인코딩을 위한 코드 공간이 존재함을 보장합니다.
*   **코드 공간 (Code Space)**: 
    -   모든 안정자 생성자의 **+1 고유 벡터(eigenvector)**인 모든 벡터를 포함하는 n-큐비트 상태 공간의 부분 공간입니다. 유효한 인코딩이 존재하는 공간입니다.
*   **예시 안정자 코드**:
    *   **3비트 반복 코드**: 
        -   비트 플립 감지용 (ZZI, IZZ) 및 위상 플립 감지용 (XXI, IXX).
    *   **9큐비트 쇼어 코드**: 
        -   3비트 반복 코드의 세 복사본을 포함하는 안정자 코드.
    *   **7큐비트 스틴 코드 (Steane Code)**: 
        -   9큐비트 쇼어 코드와 유사하게 단일 큐비트에 대한 임의 오류를 수정할 수 있지만 7큐비트만 필요.
    *   **5큐비트 코드**: 
        -   단일 큐비트 인코딩 및 임의 단일 큐비트 오류 수정이 가능한 최소 큐비트 수인 5큐비트를 사용.
    *   **EPR/GHZ 상태 안정자 코드**: 
        -   코드 공간이 1차원인 안정자 코드 (예: 벨 상태 $\|Φ⁺⟩$ 생성).
*   **인코딩 가능한 큐비트 수**: 
    -   안정자 코드의 코드 공간 차원은 **2^(n-r)**입니다. 즉, n개의 큐비트와 r개의 안정자 생성자를 사용하여 **n-r개의 논리 큐비트**를 인코딩할 수 있습니다. 이는 오류 감지/수정 능력과는 별개의 코드 공간 차원에 대한 설명.
*   **클리포드 연산 (Clifford Operations)과 인코딩**:
    *   클리포드 연산은 하다마드(Hadamard), S 게이트, CNOT 게이트로 구현될 수 있는 유니타리 연산입니다.
    *   이 연산들은 **폴리 연산을 폴리 연산으로 변환**하는 특별한 성질을 가지고 있습니다.
    *   클리포드 연산은 양자 컴퓨팅에 **보편적이지 않으며(not universal)**, 고전적으로 효율적으로 시뮬레이션될 수 있습니다 (**괴르츠만-카넬 정리, Gottesman-Knill Theorem**).
    *   안정자 코드를 사용하여 큐비트를 인코딩하는 것은 항상 **클리포드 연산**을 통해 효율적으로 수행할 수 있다.
*   **오류의 세 가지 경우**: 오류 E가 발생했을 때:
    1.  **E가 안정자에 있는 경우**: 
        -   코드 공간에 영향을 미치지 않으므로 오류가 아닙니다.
    2.  **E가 모든 안정자 생성자와 교환하지만 안정자에 없는 경우**: 
        -   코드 공간의 벡터를 변경하지만 **검출되지 않습니다**. 이는 코드의 **거리(distance)**를 정의하는 "나쁜 경우"입니다.
    3.  **E가 하나 이상의 안정자 생성자와 반교환하는 경우**: 
        -   코드가 이 오류를 **검출합니다** (증후군에 -1이 나타남).
*   **코드 거리 (Distance, d)**: 
    -   코드 공간을 비자명하게 변경하지만 코드가 검출하지 못하는 폴리 연산의 **최소 가중치**를 의미합니다. 안정자 코드는 일반적으로 **$[n, m, d]$**로 표기되며, n은 총 큐비트, m은 인코딩된 논리 큐비트 수, d는 코드 거리.
*   **오류 수정 (Error Correction)**:
    *   증후군이 나타날 때, 우리는 그 증후군을 유발한 **가장 낮은 가중치의 폴리 연산**을 보정 연산으로 선택하여 적용하는 전략을 사용합니다.
    *   이 전략은 **가중치가 d/2보다 엄격하게 작은 (즉, (d-1)/2 이하) 모든 오류를 수정**할 수 있습니다. 예를 들어, 스틴 코드(d=3)는 가중치 1 오류를 수정할 수 있습니다.
    *   **문제점**: 일반적으로 주어진 증후군을 유발하는 가장 낮은 가중치의 폴리 연산을 계산하는 것은 **계산적으로 어렵습니다**. 따라서 효율적인 오류 수정을 위해 특별히 설계된 코드를 선택하는 것이 중요합니다.

### **4. CSS 코드 (CSS Codes)**

CSS 코드는 특정 종류의 안정자 코드로, **고전 선형 코드(Classical Linear Codes)**의 쌍을 결합하여 얻는다.

*   **고전 선형 코드의 간략한 소개**:
    *   **정의**: 
        -   이진 문자열(0 또는 1)의 길이 n인 비어 있지 않은 집합 C로, C에 있는 두 이진 문자열 U와 V의 **비트별 XOR(배타적 논리합)** 연산 결과(U ⊕ V)도 C에 속하는 코드입니다. 이는 '선형'이라는 의미를 부여.
    *   모든 고전 선형 코드는 모든 비트가 0인 문자열을 포함해야 합니다.
    *   **예시**: 
        -   3비트 반복 코드 (000, 111), 743 해밍 코드 (7비트 문자열 16개로 4비트 인코딩, 거리 3). 고전 코드는 **$[n, k, d]$**로 표기됩니다.
    *   **표현 방법**:
        1.  **생성자 집합 (Generator Set)**: 코드를 생성하는 최소한의 코드 워드 집합.
        2.  **패리티 검사 (Parity Checks)**: 코드에 있는 문자열이 패리티 검사 문자열들과의 **이진 내적(binary dot product, modulo 2)**이 0이 되는 문자열들로 정의됩니다.
    *   **안정자 형식론과의 연결**: 
        -   고전 선형 코드의 패리티 검사 문자열은 **폴리 Z와 항등 행렬(Z-stabilizer generators)**만 포함하는 안정자 생성자와 동일합니다.
*   **CSS 코드의 정의**:
    *   CSS 코드는 **Z-안정자 생성자** (폴리 Z와 I만 포함)와 **X-안정자 생성자** (폴리 X와 I만 포함)만을 사용하여 표현될 수 있는 안정자 코드입니다. Y나 X와 Z가 한 안정자 생성자에 함께 나타나는 경우는 허용되지 않습니다.
    *   **중요 조건**: 
        -   Z-안정자 생성자와 X-안정자 생성자가 **서로 교환(commute)**해야 합니다. 그렇지 않으면 유효한 안정자 코드가 아닙니다.
*   **예시 CSS 코드**:
    *   **EPR(E-bit) 코드**: 
        -   하나의 Z-안정자 생성자(ZI)와 하나의 X-안정자 생성자(XX)를 가집니다.
    *   **7큐비트 스틴 코드**: 
        -   이 코드의 생성자는 Z-안정자 생성자와 X-안정자 생성자로만 구성되어 있습니다.
    *   **9큐비트 쇼어 코드**: 
        -   6개의 Z-안정자 생성자와 2개의 X-안정자 생성자를 가집니다.
*   **CSS 코드의 오류 검출 및 수정**:
    *   Z-안정자 생성자는 **X 오류(비트 플립)**를 검출하지만, **Z 오류(위상 플립)**에는 무감각합니다 (교환하기 때문).
    *   X-안정자 생성자는 **Z 오류**를 검출하지만, **X 오류**에는 무감각합니다.
    *   이러한 특성 덕분에 CSS 코드는 X 오류와 Z 오류를 **독립적으로 검출하고 수정**할 수 있습니다.
    *   본질적으로, CSS 코드는 비트 플립 오류로부터 보호하는 고전 선형 코드와 위상 플립 오류로부터 보호하는 고전 선형 코드를 결합한 것입니다. 예를 들어, 스틴 코드는 비트 플립 및 위상 플립 오류에 대해 각각 743 해밍 코드를 적용한 것과 같습니다.
    *   오류의 이산화 원리에 따라, X-안정자 생성자가 Jx 오류를 수정할 수 있고, Z-안정자 생성자가 Kz 오류를 수정할 수 있다면, CSS 코드는 **Jx와 Kz 중 더 작은 수**의 큐비트에 대한 임의 오류를 수정할 수 있습니다.
    *   **단점**: 
        -   CSS 코드의 총 안정자 생성자 수는 두 고전 코드의 패리티 검사 수의 합이므로, **인코딩할 수 있는 큐비트 수가 줄어듭니다**. 예를 들어, 743 해밍 코드는 4비트를 인코딩하지만, 7큐비트 스틴 코드는 1큐비트만 인코딩합니다 (총 6개의 안정자 생성자 때문).
