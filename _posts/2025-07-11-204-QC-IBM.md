---
title: 6차시 4:Quantum Query Algorithms(Simon's algorithm)
layout: single
classes: wide
categories:
  - Fundamentals of quantum algorithms
toc: true # 이 포스트에서 목차를 활성화
toc_sticky: true # 목차를 고정할지 여부 (선택 사항)
---


# 사이먼 알고리즘

- 출처: [Simon's algorithm](https://quantum.cloud.ibm.com/learning/en/courses/fundamentals-of-quantum-algorithms/quantum-query-algorithms/simon-algorithm)

사이먼 알고리즘은 *사이먼 문제*로 알려진 문제에 대한 양자 질의 알고리즘이다.
이것은 Deutsch-Jozsa 및 Bernstein-Vazirani 문제와 유사한 특징을 가진 약속 문제이지만, 세부 사항은 다르다.
사이먼 알고리즘은 양자 알고리즘이 고전(확률적 알고리즘 포함) 알고리즘에 비해 **지수적인 이점**을 제공한다는 점에서 중요하며, 이 알고리즘이 사용하는 기술은 피터 쇼어(Peter Shor)가 정수 분해를 위한 효율적인 양자 알고리즘을 발견하는 데 영감을 주었다.

## 1. 사이먼 문제

사이먼 문제의 입력 함수는 양의 정수 $n$과 $m$에 대해 다음과 같은 형태를 가진다.

\[
f:\Sigma^n \rightarrow \Sigma^m
\]

간단함을 위해 $m = n$인 경우로 제한할 수도 있지만, 이 가정을 함으로써 얻을 수 있는 이점은 거의 없다 — 사이먼 알고리즘과 그 분석은 기본적으로 어느 쪽이든 동일하다.
> **사이먼 문제** \
> 입력: 함수 $f:\Sigma^n \rightarrow \Sigma^m$ \
> 약속: 모든 $x,y\in\Sigma^n$에 대해 $[f(x) = f(y)] \Leftrightarrow [(x = y) \vee (x \oplus s = y)]$를 만족하는 문자열 $s\in\Sigma^n$가 존재한다 \
> 출력: 문자열 $s$

우리는 잠시 후 약속이 무엇을 의미하는지 더 잘 이해하기 위해 그 내용을 풀겠지만, 우선 이 약속은 $f$가 매우 특별한 구조를 가져야 함을 요구한다는 점을 분명히 해야 한다 — 따라서 대부분의 함수는 이 약속을 만족하지 않을 것이다.
또한 이 문제가 **실용적인 중요성을 가지도록 의도되지 않았다**는 점을 인정하는 것이 적절하다.
오히려 이 문제는 양자 컴퓨터에는 쉽고 고전 컴퓨터에는 어렵도록 맞춤 제작된 다소 인위적인 문제이다.

두 가지 주요 경우가 있다: 첫 번째 경우는 $s$가 모든 0으로 구성된 문자열 $0^n$인 경우이고, 두 번째 경우는 $s$가 모든 0으로 구성된 문자열이 아닌 경우이다.

*   **사례 1: $s=0^n.$**
    만약 $s$가 모든 0으로 구성된 문자열이라면, 약속의 필요충분조건 문장을 $[f(x) = f(y)] \Leftrightarrow [x = y]$로 간략화할 수 있다.
    이는 $f$가 **일대일 함수**임을 의미한다.

*   **사례 2: $s\neq 0^n.$**
    만약 $s$가 모든 0으로 구성된 문자열이 아니라면, 이 문자열에 대해 약속이 만족된다는 것은 $f$가 **이대일 함수**임을 의미한다. 즉, $f$의 가능한 모든 출력 문자열에 대해, $f$가 그 문자열을 출력하게 하는 입력 문자열이 정확히 두 개 있다는 뜻이다. 더욱이, 이 두 입력 문자열은 어떤 문자열 $w$에 대해 $w$와 $w \oplus s$의 형태를 가져야 한다.

약속이 충족된다면 작동하는 문자열 $s$는 오직 하나뿐일 수 있으므로, 약속을 만족하는 함수에 대해서는 항상 **유일한 정답**이 존재한다는 것을 인지하는 것이 중요하다.

다음은 문자열 $s = 011$에 대해 약속을 만족하는 $f:\Sigma^3 \rightarrow \Sigma^5$ 형태의 함수 예시이다.

<br>
$$
\begin{aligned}
f(000) & = 10011 \\
f(001) & = 00101 \\
f(010) & = 00101 \\
f(011) & = 10011 \\
f(100) & = 11010 \\
f(101) & = 00001 \\
f(110) & = 00001 \\
f(111) & = 11010
\end{aligned}
$$

8개의 다른 입력 문자열과 4개의 다른 출력 문자열이 있으며, 각각 두 번씩 나타난다 — 따라서 이것은 **이대일 함수**이다.
더욱이, 동일한 출력 문자열을 생성하는 두 개의 다른 입력 문자열에 대해, 이 두 입력 문자열의 비트별 XOR가 $011$과 같음을 알 수 있는데, 이는 둘 중 하나가 다른 하나와 $s$를 XOR한 것과 같다는 말과 동등하다.

실제 출력 문자열에 대해 중요한 유일한 점은 다른 입력 문자열 선택에 따라 그것들이 같은지 다른지 여부이다.
예를 들어, 위 예시에서 $f$의 출력으로 나타나는 문자열은 4개($10011,$ $00101,$ $00001,$ 그리고 $11010$)이다. 우리는 이 4개의 문자열을 모두 구별되는 한 다른 문자열로 대체할 수 있으며, 이 경우에도 올바른 해인 $s = 011$은 변하지 않을 것이다.

## 2. 알고리즘 설명

다음은 사이먼 알고리즘을 나타내는 양자 회로도이다.

<img src="{{site.url}}{{site.baseurl}}/assets/images/QC2/Simon.svg" alt="Example of a Boolean circuit" style="width: 50%;" />

분명히 말하면, 위쪽에는 하드마르 게이트에 의해 작동되는 $n$개의 큐비트가 있고, 아래쪽에는 질의 게이트로 직접 들어가는 $m$개의 큐비트가 있다.
이것은 우리가 수업에서 이미 논의한 알고리즘들과 매우 유사하게 보이지만, 이번에는 위상 킥백(phase kickback)이 없다. 아래쪽 $m$개의 큐비트는 모두 $\vert 0\rangle$ 상태로 질의 게이트에 들어간다.

이 회로를 사용하여 사이먼 문제를 풀기 위해서는 실제로 여러 번의 **독립적인 실행**과 그에 뒤따르는 **고전적 후처리 단계**가 필요하며, 이는 회로의 동작이 분석된 후에 설명될 것이다.

## 3. 분석

사이먼 알고리즘의 분석은 Deutsch-Jozsa 알고리즘과 유사한 방식으로 시작된다.
상위 $n$개 큐비트에 대해 첫 번째 하드마르 게이트 층이 수행된 후, 상태는 다음과 같이 된다.

\[
\frac{1}{\sqrt{2^n}} \sum_{x\in\Sigma^n} \vert 0^m \rangle \vert x\rangle.
\]

$U_f$가 수행되면, 함수 $f$의 출력이 하위 $m$개 큐비트의 모든 0 상태에 XOR되므로, 상태는 다음과 같이 된다.

\[
\frac{1}{\sqrt{2^n}} \sum_{x\in\Sigma^n} \vert f(x) \rangle \vert x\rangle.
\]

두 번째 하드마르 게이트 층이 수행되면, 이전에 사용했던 하드마르 게이트 층의 작용에 대한 동일한 공식을 사용하여 다음 상태를 얻는다.
\[
\frac{1}{2^n} \sum_{x\in\Sigma^n} \sum_{y\in\Sigma^n} (-1)^{x\cdot y} \vert f(x) \rangle \vert y\rangle
\]

이 시점에서, 분석은 이 수업의 이전 알고리즘들과 달라진다.

우리는 각 가능한 문자열 $y\in\Sigma^n$에 대해 측정 결과가 나올 확률에 관심이 있다.
*양자 정보의 기초* 과정의 *다중 시스템* 수업에서 설명된 측정 분석 규칙을 통해, 문자열 $y$를 얻을 확률 $p(y)$는 다음과 같다는 것을 알 수 있다.

\[
p(y) = \left\|\frac{1}{2^n} \sum_{x\in\Sigma^n} (-1)^{x\cdot y} \vert f(x) \rangle \right\|^2.
\]

이 확률들을 더 잘 이해하기 위해, 우리는 약간의 표기법과 용어가 더 필요할 것이다.
첫째, 함수 $f$의 **치역(range)**은 모든 출력 문자열을 포함하는 집합이다.

\[
\operatorname{range}(f) = \{ f(x) : x\in \Sigma^n \}
\]

둘째, 치역($\operatorname{range}(f)$) 내의 각 문자열 $z$에 대해, 함수가 이 출력 문자열 $z$로 평가되게 하는 모든 입력 문자열의 집합을 $f^{-1}(\{z\})$로 표현할 수 있다.
\[
f^{-1}(\{z\}) = \{ x\in\Sigma^n : f(x) = z \}
\]

집합 $f^{-1}(\{z\})$는 $f$에 의한 $\{z\}$의 **원상(preimage)**으로 알려져 있다.
우리는 $\{z\}$ 대신 어떤 집합에 대한 $f$의 원상을 유사한 방식으로 정의할 수 있다 — 그것은 $f$가 그 집합으로 매핑하는 모든 원소의 집합이다.
(이 표기법은 존재하지 않을 수도 있는 함수 $f$의 **역함수(inverse)**와 혼동해서는 안 된다.좌변의 인수가 원소 $z$가 아닌 집합 $\{z\}$라는 사실이 이러한 혼동을 피할 수 있게 해주는 단서이다.)

이 표기법을 사용하여, 위 확률 표현식의 합을 분할하여 다음을 얻을 수 있다.
\[
p(y) =
\left\|
\frac{1}{2^n}
\sum_{z\in\operatorname{range}(f)}
\Biggl(\sum_{x\in f^{-1}(\{z\})} (-1)^{x\cdot y}\Biggr)
\vert z \rangle
\right\|^2.
\]

모든 문자열 $x\in\Sigma^n$는 두 개의 합산에 의해 정확히 한 번씩 표현된다 — 우리는 기본적으로 함수 $f$를 평가할 때 그들이 생성하는 출력 문자열 $z = f(x)$에 따라 이 문자열들을 별도의 '버킷'에 넣은 다음, 모든 버킷에 대해 별도로 합산하는 것이다.

이제 유클리드 노름 제곱을 평가하여 다음을 얻을 수 있다.
\[
p(y) = \frac{1}{2^{2n}}
\sum_{z\in\operatorname{range}(f)}
\left\vert \sum_{x\in f^{-1}(\{z\})} (-1)^{x\cdot y} \right\vert^2.
\tag{1}
\]

이 확률들을 더 단순화하기 위해, 임의의 $z\in\operatorname{range}(f)$ 선택에 대한 다음 값을 살펴보자.
\[
\left\vert \sum_{x\in f^{-1}(\{z\})} (-1)^{x\cdot y} \right\vert^2
\tag{1}
\]

만약 $s = 0^n$인 경우라면, $f$는 일대일 함수이므로 모든 $z\in\operatorname{range}(f)$에 대해 $f^{-1}(\{z\})$에는 항상 단 하나의 원소 $x$만 존재한다.
이 경우 표현식 (1)의 값은 $1$이다.

반면에, $s\neq 0^n$이라면, 집합 $f^{-1}(\{z\})$에는 정확히 두 개의 문자열이 있다.
정확히 말해, 만약 우리가 이 두 문자열 중 하나를 $w\in f^{-1}(\{z\})$로 선택한다면, 사이먼 문제의 약속에 의해 다른 문자열은 $w \oplus s$여야 한다.
이러한 관찰을 사용하여 우리는 (1)을 다음과 같이 단순화할 수 있다.
\[
\left\vert \sum_{x\in f^{-1}(\{z\})} (-1)^{x\cdot y} \right\vert^2
 = \Bigl\vert (-1)^{w\cdot y} + (-1)^{(w\oplus s)\cdot y} \Bigr\vert^2 \]
 \[= \Bigl\vert (-1)^{w\cdot y} \Bigl(1 + (-1)^{s\cdot y}\Bigr) \Bigr\vert^2 
 = \Bigl\vert 1 + (-1)^{y\cdot s} \Bigr\vert^2 \]
 $$ \qquad  = \begin{cases}
4 & y \cdot s = 0 \\
0 & y \cdot s = 1 
\end{cases}$$\


따라서, 값 (1)은 두 경우 모두에서 $z\in\operatorname{range}(f)$의 특정 선택과 무관하다는 것이 밝혀졌다.
이제 이전과 동일한 두 가지 경우를 각각 살펴보면서 분석을 마칠 수 있다.

*   **사례 1: $s = 0^n.$** 이 경우 함수 $f$는 일대일이므로, $2^n$개의 문자열 $z\in\operatorname{range}(f)$가 존재하며, 우리는 다음을 얻는다.
    \[
    p(y) = \frac{1}{2^{2n}} \cdot 2^n = \frac{1}{2^n}.
    \]
    즉, 측정 결과는 **균일하게 무작위로 선택된** 문자열 $y\in\Sigma^n$이다.

*   **사례 2: $s \neq 0^n.$**
    이 경우 $f$는 이대일이므로, $\operatorname{range}(f)$에는 $2^{n-1}$개의 원소가 있다.
    위에서 얻은 공식을 사용하여, 각 $y\in\Sigma^n$를 측정할 확률은 다음과 같다고 결론 내린다.
    <br>
    $$
    p(y)
    = \frac{1}{2^{2n}} \sum_{z\in\operatorname{range}(f)}
    \Biggl\vert \sum_{x\in f^{-1}(\{z\})} (-1)^{x\cdot y} \Biggr\vert^2
    =
    \begin{cases}
    \frac{1}{2^{n-1}} & y \cdot s = 0\\[1mm]
    0 & y \cdot s = 1
    \end{cases}
    $$

    즉, 우리는 집합 $\{y\in\Sigma^n : y \cdot s = 0\}$에서 **균일하게 무작위로 선택된** 문자열을 얻으며, 이 집합에는 $2^{n-1}$개의 문자열이 포함되어 있다. ($s\neq 0^n$이기 때문에, 길이 $n$의 이진 문자열 중 정확히 절반은 $s$와 이진 점 곱이 $1$이고 나머지 절반은 $0$이라는 것을 우리는 Bernstein-Vazirani 문제에 대한 Deutsch-Jozsa 알고리즘 분석에서 이미 관찰했다.)

### 3.1 고전적 후처리

이제 우리는 사이먼 알고리즘을 위한 양자 회로를 실행할 때 가능한 측정 결과에 대한 확률이 무엇인지 안다.
이것이 $s$를 결정하기에 충분한 정보인가?

답은 '예'이다. 단, 우리는 이 과정을 여러 번 반복하고, 회로를 충분히 많이 실행함으로써 매우 작게 만들 수 있는 어떤 확률로 실패할 수도 있다는 것을 받아들일 의향이 있다면 말이다.
본질적인 아이디어는 회로의 각 실행이 $s$에 대한 통계적 증거를 제공하며, 우리가 회로를 충분히 많이 실행한다면 그 증거를 사용하여 **매우 높은 확률로 $s$를 찾을 수 있다**는 것이다.

우리가 회로를 $k$번 독립적으로 실행한다고 가정하자. 여기서 $k = n + 10$이다.
이 특정 반복 횟수에 특별한 점은 없다 — 우리가 감수할 수 있는 실패 확률에 따라 $k$를 더 크게(또는 더 작게) 설정할 수 있다.
$k = n + 10$으로 선택하면 $s$를 복구할 확률이 **99.9%보다 높음**을 보장할 것이다.

회로를 $k$번 실행함으로써, 우리는 $y^1,...,y^{k} \in \Sigma^n$ 문자열을 얻는다.
분명히 말하면, 여기의 위 첨자는 이 문자열들의 이름의 일부이며, 비트의 지수나 인덱스가 아니다. 따라서 우리는 다음을 얻는다.
<br>
$$
\begin{aligned}
y^1 & = y^1_{n-1} \cdots y^1_{0}\\[1mm]
y^2 & = y^2_{n-1} \cdots y^2_{0}\\[1mm]
& \;\; \vdots\\[1mm]
y^{k} & = y^{k}_{n-1} \cdots y^{k}_{0}
\end{aligned}
$$

이제 우리는 이 문자열들의 비트를 이진 값 항목으로 사용하여 $k$행 $n$열의 행렬 $M$을 형성한다.
<br>
$$
M = \begin{pmatrix}
y^1_{n-1} & \cdots & y^1_{0}\\[1mm]
y^2_{n-1} & \cdots & y^2_{0}\\[1mm]
\vdots & \ddots & \vdots \\[1mm]
y^{k}_{n-1} & \cdots & y^{k}_{0}
\end{pmatrix}
$$

현재 시점에서는 $s$가 무엇인지 알지 못한다 — 우리의 목표는 이 문자열을 찾는 것이다.
하지만 우리가 문자열 $s$를 안다고 잠시 상상해보자. 그리고 문자열 $s = s_{n-1} \cdots s_0$의 비트로부터 다음과 같이 열 벡터 $v$를 형성한다.
<br>
$$
v = \begin{pmatrix}
s_{n-1}\\
\vdots\\
s_0
\end{pmatrix}
$$

행렬-벡터 곱셈 $M v$를 모듈로 2로 수행하면 — 즉, 평소처럼 곱셈을 수행한 다음 결과 항목을 2로 나눈 나머지를 취하면 — 모든 0 벡터를 얻는다.

<br>
$$
M v = \begin{pmatrix}
y^1 \cdot s\\
y^2 \cdot s\\
\vdots\\[1mm]
y^{k} \cdot s
\end{pmatrix}
= \begin{pmatrix}
0\\
0\\
\vdots\\[1mm]
0
\end{pmatrix}
$$

즉, 방금 설명한 대로 열 벡터 $v$로 취급될 때, 우리가 연산을 모듈로 2로 수행한다면 문자열 $s$는 항상 행렬 $M$의 **영공간(null space)**의 원소가 될 것이다.
이는 $s = 0^n$인 경우와 $s\neq 0^n$인 경우 모두에 해당한다.
더 정확히 말하면, 모든 0 벡터는 항상 $M$의 영공간에 있으며, $s\neq 0^n$인 경우에는 $s$의 비트들을 원소로 하는 벡터가 함께 존재한다.

남은 질문은 $0^n$과 $s$에 해당하는 벡터 외에 $M$의 영공간에 다른 벡터가 있을지 여부이다.
답은 $k$가 증가할수록 그럴 가능성이 낮아진다는 것이다 — 그리고 $k = n + 10$으로 선택하면, $M$의 영공간은 **99.9% 이상의 확률**로 $0^n$과 $s$에 해당하는 벡터 외에 다른 벡터를 포함하지 않을 것이다.
더 일반적으로, 양의 정수 $r$을 임의로 선택하여 $k = n + 10$을 $k = n + r$로 대체하면, $0^n$과 $s$에 해당하는 벡터만 $M$의 영공간에 존재할 확률은 최소한 $1 - 2^{-r}$이다.

선형 대수를 사용하여, 모듈로 2로 $M$의 영공간에 대한 설명을 **효율적으로 계산**할 수 있다.
구체적으로, 이는 *가우스 소거법*을 사용하여 수행할 수 있는데, 이는 실수나 복소수에 대한 연산과 마찬가지로 모듈로 2 연산에서도 동일하게 작동한다.
$0^n$과 $s$에 해당하는 벡터만 $M$의 영공간에 존재하는 한(이는 높은 확률로 발생한다), 이 계산 결과를 통해 $s$를 추론할 수 있다.

### 3.2 고전적 난이도

*고전적* 질의 알고리즘은 사이먼 문제를 해결하는 데 얼마나 많은 질의를 필요로 하는가?
답은: 일반적으로 **매우 많다**.

이 문제의 고전적 난이도에 대해 다양한 정확한 진술이 가능하며, 여기 그 중 하나가 있다.
만약 우리가 어떤 확률적 질의 알고리즘을 가지고 있고, 그 알고리즘이 $n$에 대해 **지수적인** 질의 수인 $2^{n/2 - 1} - 1$보다 적은 질의를 한다면, 그 알고리즘은 **적어도 1/2의 확률로 사이먼 문제를 해결하는 데 실패할 것이다**.

때로는 이와 같은 불가능성 결과를 증명하는 것이 매우 어려울 수 있지만, 이 증명은 기본적인 확률 분석을 통해 그리 어렵지 않다.
그러나 여기서는 그 기본적인 직관에 대해서만 간략하게 살펴볼 것이다.

우리는 숨겨진 문자열 $s$를 찾으려고 하지만, 동일한 출력 값을 가지는 두 문자열에 대해 함수를 질의하지 않는 한 $s$에 대한 정보는 매우 제한적일 것이다.
직관적으로 말해, 우리가 알게 될 것은 숨겨진 문자열 $s$가 우리가 질의한 **어떤 두 개의 서로 다른 문자열의 XOR가 아니라는 것**뿐이다.
그리고 우리가 $2^{n/2 - 1} - 1$개 미만의 문자열을 질의한다면, 그렇게 할 만큼 충분한 문자열 쌍이 없기 때문에 우리가 아직 배제하지 못한 $s$에 대한 많은 선택지가 여전히 남아있을 것이다.
이것은 공식적인 증명이 아니라, 기본적인 아이디어일 뿐이다.

요약하자면, 사이먼 알고리즘은 질의 모델 내에서 고전 알고리즘에 비해 **양자 알고리즘의 놀라운 이점**을 우리에게 제공한다.
특히, 사이먼 알고리즘은 함수 입력 비트 수 $n$에 대해 **선형적인 수의 질의**로 사이먼 문제를 해결하는 반면, 어떤 고전 알고리즘이라도(확률적인 알고리즘이라 할지라도) 합리적인 성공 확률로 사이먼 문제를 해결하기 위해서는 $n$에 대해 **지수적인 수의 질의**를 해야 한다.